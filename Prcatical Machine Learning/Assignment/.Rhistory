#df<-rbind(contents)
#finaldf
# class(finaldf["sulfate"])
mean(as.numeric(unlist(finaldf[pollutant])))
}
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean<-function(directory, pollutant, id=1:332){
fulldirectory = paste(getwd(),"/", directory,"/",sep='')
file_list<-list.files(path = directory, pattern = "*.csv")
id_list <- c(id)
df <- data.frame()
df <-
do.call("rbind.data.frame",
lapply(file_list,
function(x)
read.csv(paste(directory, x, sep='/'), header= TRUE,
stringsAsFactors = FALSE)))
specdf<-df[df$ID %in% id_list,]
good<-complete.cases(specdf)
finaldf<-specdf[good,]
#contents<-read.csv(paste(directory,(file_list), sep=''), header=TRUE, stringsAsFactors = FALSE)
#df<-rbind(contents)
#finaldf
# class(finaldf["sulfate"])
mean(as.numeric(unlist(finaldf[pollutant])))
}
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean<-function(directory, pollutant, id=1:332){
fulldirectory = paste(getwd(),"/", directory,"/",sep='')
file_list<-list.files(path = fulldirectory, pattern = "*.csv")
id_list <- c(id)
df <- data.frame()
df <-
do.call("rbind.data.frame",
lapply(file_list,
function(x)
read.csv(paste(fulldirectory, x, sep='/'), header= TRUE,
stringsAsFactors = FALSE)))
specdf<-df[df$ID %in% id_list,]
good<-complete.cases(specdf)
finaldf<-specdf[good,]
#contents<-read.csv(paste(directory,(file_list), sep=''), header=TRUE, stringsAsFactors = FALSE)
#df<-rbind(contents)
#finaldf
# class(finaldf["sulfate"])
#mean(as.numeric(unlist(finaldf[pollutant])))
fulldirectory
}
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean<-function(directory, pollutant, id=1:332){
fulldirectory = paste(getwd(),"/", directory,"/",sep='')
file_list<-list.files(path = directory, pattern = "*.csv")
id_list <- c(id)
df <- data.frame()
df <-
do.call("rbind.data.frame",
lapply(file_list,
function(x)
read.csv(paste(fulldirectory, x, sep=''), header= TRUE,
stringsAsFactors = FALSE)))
specdf<-df[df$ID %in% id_list,]
good<-complete.cases(specdf)
finaldf<-specdf[good,]
#contents<-read.csv(paste(directory,(file_list), sep=''), header=TRUE, stringsAsFactors = FALSE)
#df<-rbind(contents)
#finaldf
# class(finaldf["sulfate"])
#mean(as.numeric(unlist(finaldf[pollutant])))
file_list
}
pollutantmean("specdata", "sulfate", 1:10)
idahoData<-read.table("./data/idaho.csv", sep=",", header=TRUE)
data.table(idahoData)
install.packages("data.table")
data.table(idahoData)
library(data.table)
data.table(idahoData)
tables()
data.table(idahoData)
id_table<-data.table(idahoData)
tables()
id_table$VAL == 24
count(id_table$VAL == 24)
nrow(id_table$VAL == 24)
sum(id_table$VAL == 24)
sum((id_table$VAL == 24), na.rm = TRUE)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile="./data/NGAP.xlsx")
list.files
list.files("./data")
colIndex<-7:15
rowIndex<-18-23
NGAPDataSubset<-read.xlsx("./data/NGAP.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
library(xlsx)
install.packages("xlsx")
library(xlsx)
library(xlsx)
install.packages("xlsx")
library(xlsx)
install.packages("rJava")
library(xlsx)
clear()
library(xlsx)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7')
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7'
library(rJava)
library(rJava)
library(rJava)
library(xlsx)
dat<-read.xlsx("./data/NGAP.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
colIndex<-7:15
rowIndex<-18-23
dat<-read.xlsx("./data/NGAP.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
download.file(fileUrl, destfile="./data/NGAP.xlsx", mode="wb")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile="./data/NGAP.xlsx", mode="wb")
dat<-read.xlsx("./data/NGAP.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
install.packages("XML")
library(XML)
fileURL<-https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-XMLTreeParse(fileURL, useInternal=TRUE)
doc<-xmlTreeParse(fileURL, useInternal=TRUE)
doc
doc<-xmlTreeParse(fileURL, useInternalNodes = TRUE)
library(RCurl)
xData <- getURL(fileURL)
doc <- xmlParse(xData)
doc
zipcode<-xpathSApply(doc, "//zipcode",xmlValue)
zipcode
nrow(zipcode= "21231")
nrow(zipcode)
class(zipcode)
zipcode[,1]=="21231"
zipcode =="21231"
length(zipcode)
length(zipcode=="21231")
length(zipcode =="21231")
table(zipcode =="21231")
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
library(data.table)
?fread
fread(fileURL)
DT<-fread(fileURL)
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time()
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
DT[,mean(pwgtp15),by=SEX]
mean(DT$pwgtp15,by=DT$SEX)
system.time()rowMeans(DT)[DT$SEX==1]
system.time(rowMeans(DT)[DT$SEX==1])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(pwgtp15))
sum(dat$Zip*dat$Ext,na.rm=T)
system.time(DT[,mean(pwgtp15),by=SEX])
install.packages("httpuv")
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("GitHubAPI", "4c036bfc69b006b579ad","6d378117b5f631178d6a536f70c5f71e4549f207")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(req))
json2 = jsonlite::fromJSON(toJSON(content(req)))
json2
head(json2)
json2[1, 1:5]
names(json2)
json2[1,46]
json2[,46]
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readlines(con)
library(html)
htmlCode = readLines(con)
htmlCode
nchar(10)
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
data <- read.fwf("./data/getdata-wksst8110.for", c(10,9,4,9,4,9,4,9,4), header = FALSE)
sum(data$V4)
data <- read.fwf("./data/getdata-wksst8110.for",header = FALSE)
data <- read.fwf("./data/getdata-wksst8110.for", c(10,9,4,9,4,9,4,9,4), header = FALSE)
data
sum(data[,4])
data <- read.fwf("./data/getdata-wksst8110.for",header = FALSE, skip=3)
data <- read.fwf("./data/getdata-wksst8110.for", c(10,9,4,9,4,9,4,9,4), skip=3, header = FALSE)
sum(data$V4)
sum(as.numeric(data$V4))
data <- read.fwf("./data/getdata-wksst8110.for", c(10,9,4,9,4,9,4,9,4), header = FALSE)
sum(as.numeric(data$V4))
data <- read.fwf("./data/getdata-wksst8110.for", c(10,9,4,9,4,9,4,9,4), skip=3, header = FALSE)
sum(as.numeric(data[,4]))
getwd()
dt<-data.table(read.csv("./data/acs.csv"))
library(data.table)
dt<-data.table(read.csv("./data/acs.csv"))
dt
head(dt)
dt_col<-names(dt)
dt_col
dt_col<-dt[,grep("^wgtp", colnames(dt))]
dt_col
dt_col<-dt[,grep("^wgtp", names(dt))]
dt_col<-grep("^wgtp", names(dt))
dt_colm<-grep("^wgtp", names(dt))
dt_colm<-grepl("^wgtp", names(dt))
dt2<-dt[,dt_col]
dt2<-dt(dt_col)
dt_col<-names(dt)
dt_col<-names(dt)="^wgtp"
dt_col<-dt[,grep("^wgtp", names(dt), value = TRUE)]
dt_col<-dt[,grep("WGTP|^wgtp", names(dt), value = TRUE)]
dt_col
strsplit(dt_col, "wgtp")
dt_col<-names(dt)
strsplit(dt_col, "wgtp")
ls()
rm(ls())
rm(list=ls())
library(data.table)
dt<-data.table(read.csv("./data/gdp.csv", skip = 5, header = FALSE))
dt<-data.table(read.csv("./data/gdp.csv", skip = 5, header = FALSE, nrows = 190))
dt
dt<-dt[X!=""]
dt<-dt[,list(X, X.1, X.3, X.4)]
names(dt)
dt<-dt[,list(V1, V2, V3, V4)]
dt<-data.table(read.csv("./data/gdp.csv", skip = 5, header = FALSE, nrows = 190))
dt<-dt[V1!=""]
dt<-dt[,list(V1, V2, V4, V5)]
dt
mean(dt$V5)
mean(As.numeric(dt$V5)
mean(As.numeric(dt$V5))
mean(as.numeric(dt$V5))
mean(as.numeric(gsub(",","",dt$V5)))
grep("^United",dt$V4)
grep("^United",as.character(dt$V4))
grep("*United",as.character(dt$V4))
dt_country<-data.table(read.csv("./data/country.csv"))
dt_country
dt_merge<-merge(dt, dt_country, by.x=V1, by.y = CountryCode)
dt_merge<-merge(dt, dt_country, by.x = "V1", by.y = "CountryCode")
grep("June", dt_merge$Special.Notes)
length(grep("June", dt_merge$Special.Notes))
length(grep("Fiscal Year End:June", dt_merge$Special.Notes))
length(grep("Fiscal Year End: June", dt_merge$Special.Notes))
length(grep("Fiscal Year End: June", dt_merge$Special.Notes, ignore.case = TRUE))
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
library(lubridate)
?lubridate
class(sampleTimes)
length(subset(sampleTimes, year = 2012))
sampleTimes<-ymd(sampleTimes)
length(subset(sampleTimes, year = 2012))
sampleTimes
length(sampleTimes(year=2012))
length(subset(sampleTimes, year(sampleTimes) == 2012 & wday(sampleTimes, label=T) == "Mon"))
length(subset(sampleTimes, year(sampleTimes) == 2012)
length(subset(sampleTimes, year(sampleTimes) == 2012))
length(subset(sampleTimes, year(sampleTimes) == 2012))
install.packages("ggplot2")
library(mtcars)
fit<-lm(mpg~factor(cyl)+weight, mtcars)
data(mtcars)
fit<-lm(mpg~factor(cyl)+weight, mtcars)
fit<-lm(mpg~factor(cyl)+wt, mtcars)
summary(fit)$coefficient
fit1<-lm(mpg~factor(cyl), mtcars)
summary(fit1)$coefficient
fit2<-lm(mpg~factor(cyl)*wt, mtcars)
anova(fit, fit2, test = "Chisq")
fit3<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit3)$coefficient
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit4<-lm(y~x)
hatvalues(fit4)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit5<-lm(y~x)
dfbetas(fit5)
library(MASS)
data(shuttle)
str(shuttle)
shuttle$usebin <- as.numeric(shuttle$use == "auto") # create a binary variable
fit <- glm(usebin ~ factor(wind) - 1, family = "binomial", data = shuttle)
Coef <- coef(summary(fit))
coef.odds <- exp(c(Coef[1, 1], Coef[2, 1]))
(odds.ratio <- coef.odds[1] / coef.odds[2]) # "head" is the reference
fit2 <- glm(usebin ~ factor(wind) + factor(magn) - 1, family = "binomial", data = shuttle)
(Coef2 <- coef(summary(fit2)))
coef2.odds <- exp(c(Coef2[1, 1], Coef2[2, 1]))
(odds2.ratio <- coef2.odds[1] / coef2.odds[2]) # "head" is the reference
data(InsectSprays)
str(InsectSprays)
fit4 <- glm(count ~ factor(spray), family = "poisson", data = InsectSprays)
(Coef4 <- coef(summary(fit4))) # "A" is the reference
exp(Coef4[1, 1]) / exp(Coef4[1, 1] + Coef4[2, 1])
data(mtcars)
str(mtcars)
mtcars$am<-as.factor(mtcars$am)
levels(mtcars$am)<-c("AT", "MT")
library(ggplot2)
ggplot(data = mtcars, aes(mtcars$mpg)) + geom_histogram()
ggplot(data = mtcars, aes(mpg~am)) + geom_histogram()
ggplot(data = mtcars, aes(mtcars$mpg~mtcars$am)) + geom_histogram()
ggplot(data = mtcars, aes(factor(am))) + geom_histogram()
ggplot(data = mtcars, aes(am)) + geom_boxplot()
ggplot(data = mtcars, aes(mtcars$am)) + geom_boxplot()
ggplot(data = mtcars, aes(factor(mtcars$am))) + geom_boxplot()
ggplot(data = mtcars, aes((mtcars$am)) + geom_boxplot()
)
ggplot(data = mtcars, aes(factor(mtcars$am))) + geom_boxplot()
ggplot(data = mtcars, aes(mtcars$am)) + geom_boxplot()
ggplot(data = mtcars, aes(mtcars$am)) + geom_histogram()
ggplot(data = mtcars, aes(mtcars$am)) + geom_histogram()
levels(mtcars$am)<-c("AT", "MT")
ggplot(data = mtcars, aes(am) + geom_histogram()
)
ggplot(data = mtcars, aes(am)) + geom_histogram()
ggplot(data = mtcars, aes(mtcars$am)) + geom_histogram()
ggplot(data = mtcars, aes(mpg)) + geom_histogram()
ggplot(data = mtcars, aes(mpg)) + geom_histogram()
ggplot(data = mtcars, aes(mpg)) + geom_histogram() + facet_grid(.~am)
ggplot(data = mtcars, aes(mpg)) + geom_boxplot()
ggplot(data = mtcars, aes(group = mpg)) + geom_boxplot()
ggplot(data = mtcars, aes(mpg)) + geom_boxplot(group = am)
ggplot(data = mtcars, aes(mpg)) + geom_boxplot(group = mtcars$am)
ggplot(data = mtcars, aes(mpg)) + geom_boxplot()
ggplot(data = mtcars, aes(mt,mpg)) + geom_boxplot()
ggplot(data = mtcars, aes(am,mpg)) + geom_boxplot()
corr <- select(mtcars, mpg,cyl,disp,wt,am)
pairs(corr)
library(lmtest)
install.packages("lmtest")
library(lmtest)
corr <- select(mtcars, mpg,cyl,disp,wt,am)
pairs(corr)
corr <- select(mtcars, mpg,cyl,disp,wt,am)
library(dplyr)
corr <- select(mtcars, mpg,cyl,disp,wt,am)
pairs(corr)
fit_1 <-lm(mpg~am, data = mtcars)
summary(fit)
summary(fit_1)
aggregate(mpg~am, data=mtcars, mean)
atData<-mtcars[mtcars$am == "AT",]
mtData<-mtcars[mtcars$am == "MT",]
t.test(atData$mpg, mtData$mpg)
fit_2 <-lm(mpg~., data = mtcars)
summary(fit_2)
fit_3<-lm(mpg~cyl+disp+wt+am, data = mtcars)
summary(fit_3)
fit_3<-lm(mpg~disp+wt+am, data = mtcars)
summary(fit_3)
fit_3<-lm(mpg~wt+am, data = mtcars)
summary(fit_3)
fit_3<-lm(mpg~cyl+disp+wt+am+qsec, data = mtcars)
summary(fit_3)
corr <- select(mtcars, mpg,cyl,disp,wt,qsec, am)
pairs(corr)
par(mfrow = c(2,2))
plot(fit_3)
ggplot(data = mtcars, aes(mpg)) + geom_histogram() + facet_grid(.~am) + labs(x = "Miles per Gallon", y = "Frequency", main = "MPG Histogram for AT and MT cars")
ggplot(data = mtcars, aes(am,mpg)) + geom_boxplot() + labs(x= "Transmission", y = "MPG", main = "MPG: AT vs MT")
ggplot(data = mtcars, aes(am,mpg)) + geom_boxplot() + labs(x= "Transmission", y = "MPG", title = "MPG: AT vs MT")
fit_2 <-lm(mpg~., data = mtcars)
summary(fit_2)
fit_3<-lm(mpg~cyl+disp+wt+am+qsec, data = mtcars)
summary(fit_3)
install.packages("latex2exp")
install.packages("pdftools")
rm(list = ls())
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrPlot)
set.seed(11111)
#loading data
training<-read.csv("pml-training.csv")
#test_set<- read.csv("pml-testing.csv")
##partition 70% of training set
train_partition<-createDataPartition(training$classe, p = 0.7, list = FALSE)
train_set<-training[train_partition,]
test_set<-training[-train_partition,]
dim(train_set)
dim(test_set)
#data cleaning
##remove mostly NA variables
NAs <- sapply(train_set, function(x) mean(is.na(x)))>.95
train_set<-train_set[, NAs == FALSE]
test_set<-test_set[, NAs == FALSE]
##Near Zero Variance
nearZeroVariance <- nearZeroVar(train_set)
train_set <- train_set[,-nearZeroVariance]
test_set <- test_set[,-nearZeroVariance]
##Remove columns 1 to 5 which are only used for identification
train_set <-train_set[,-(1:5)]
test_set <-test_set[,-(1:5)]
library(corrplot)
setwd("C:/Users/user/Desktop/Data Science/Coursera/Practical Machine Learning/Assignment")
set.seed(11111)
#loading data
training<-read.csv("pml-training.csv")
#test_set<- read.csv("pml-testing.csv")
##partition 70% of training set
train_partition<-createDataPartition(training$classe, p = 0.7, list = FALSE)
train_set<-training[train_partition,]
test_set<-training[-train_partition,]
dim(train_set)
dim(test_set)
#data cleaning
##remove mostly NA variables
NAs <- sapply(train_set, function(x) mean(is.na(x)))>.95
train_set<-train_set[, NAs == FALSE]
test_set<-test_set[, NAs == FALSE]
##Near Zero Variance
nearZeroVariance <- nearZeroVar(train_set)
train_set <- train_set[,-nearZeroVariance]
test_set <- test_set[,-nearZeroVariance]
##Remove columns 1 to 5 which are only used for identification
train_set <-train_set[,-(1:5)]
test_set <-test_set[,-(1:5)]
corMatrix <- cor(train_set[, -54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower",
tl.cex = 0.8, tl.col = rgb(0, 0, 0))
set.seed(11111)
controlRandForest<-trainControl(method = "cv", number = 3, verboseIter = FALSE)
modelFitRandForest<-train(classe ~ ., data = train_set, method = "rf", trControl = controlRF)
modelFitRandForest$finalModel
modelFitRandForest<-train(classe ~ ., data = train_set, method = "rf", trControl = controlRandForest)
modelFitRandForest$finalModel
predictRandForest <- predict(modelFitRandForest, newdata = test_set)
confusionMatrixRandForest <- confusionMatrix(predictRandForest, test_set$classe)
confusionMatrixRandForest
set.seed(11111)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modelFitGBM <-train(classe ~ ., data = train_set, method = "gbm", trControl = controlGBM, verbose = FALSE)
set.seed(11111)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modelFitGBM <-train(classe ~ ., data = train_set, method = "gbm", trControl = controlGBM, verbose = FALSE)
modelFitGBM$finalModel
predictGBM <-predict(modFitGBM, newdata = TestSet)
confusionMatrixGBM <- confusionMatrix(predictGBM, test_set$classe)
confusionMatrixGBM
predictGBM <-predict(modelFitGBM, newdata = TestSet)
confusionMatrixGBM <- confusionMatrix(predictGBM, test_set$classe)
confusionMatrixGBM
predictGBM <-predict(modelFitGBM, newdata = TestSet)
confusionMatrixGBM <- confusionMatrix(predictGBM, test_set$classe)
confusionMatrixGBM
predictGBM <-predict(modelFitGBM, newdata = test_set)
confusionMatrixGBM <- confusionMatrix(predictGBM, test_set$classe)
confusionMatrixGBM
confusionMatrixRandForest
testing<- read.csv("pml-testing.csv")
predictTest<-predict(modelFitRandForest, newdata = testing)
predictTest
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
#Load training and test datasets
training<-read.csv("pml-training.csv")
testing<- read.csv("pml-testing.csv")
# Chunk 3
train_partition<-createDataPartition(training$classe, p = 0.7, list = FALSE)
train_set<-training[train_partition,]
test_set<-training[-train_partition,]
# Chunk 4
NAs <- sapply(train_set, function(x) mean(is.na(x)))>.95
train_set<-train_set[, NAs == FALSE]
test_set<-test_set[, NAs == FALSE]
# Chunk 5
nearZeroVariance <- nearZeroVar(train_set)
train_set <- train_set[,-nearZeroVariance]
test_set <- test_set[,-nearZeroVariance]
# Chunk 6
train_set <-train_set[,-(1:5)]
test_set <-test_set[,-(1:5)]
# Chunk 7
set.seed(11111)
controlRandForest<-trainControl(method = "cv", number = 3, verboseIter = FALSE)
modelFitRandForest<-train(classe ~ ., data = train_set, method = "rf", trControl = controlRandForest)
